name: Data Pipeline CI

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'pipelines/**'
      - 'pyproject.toml'
      - '.github/workflows/data-pipeline-ci.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'pipelines/**'
      - 'pyproject.toml'
  workflow_dispatch:
    # Allow manual triggering

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ".[dev,test]"
          
      - name: Run code formatting check
        run: |
          black --check pipelines/
          isort --check pipelines/
          
      - name: Run linting
        run: |
          flake8 pipelines/

  test:
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ".[dev,test]"
          
      - name: Run tests for all pipelines
        env:
          PYTHONPATH: ${{ github.workspace }}
          BQ_PROJECT_ID: test-project
          BQ_STAGING_DATASET_ID: test_dataset
          BQ_DESTINATION_DETAILS_TABLE_ID: test_destinations
          GCS_BUCKET_NAME: test-bucket
          GCS_WEATHER_BUCKET_NAME: test-weather-bucket
          TESTING: "true"
        run: |
          mkdir -p junit
          pytest pipelines/ --junitxml=junit/test-results.xml
          
      - name: Run specific scrapping pipeline tests
        env:
          PYTHONPATH: ${{ github.workspace }}
          BQ_PROJECT_ID: test-project
          BQ_STAGING_DATASET_ID: test_dataset
          BQ_DESTINATION_DETAILS_TABLE_ID: test_destinations
          GCS_BUCKET_NAME: test-bucket
          GCS_WEATHER_BUCKET_NAME: test-weather-bucket
          TESTING: "true"
        run: |
          mkdir -p junit/scrapping_dest_details
          mkdir -p coverage-reports/scrapping_dest_details
          cd pipelines/scrapping_dest_details
          python -m tests.run_tests --with-coverage --junit-xml=../../junit/scrapping_dest_details/test-results.xml --html-report=../../coverage-reports/scrapping_dest_details
          
      - name: Upload test results
        uses: actions/upload-artifact@v4
        if: always()
        with:
          name: test-results
          path: junit/
          
      - name: Upload coverage reports
        uses: actions/upload-artifact@v4
        if: success()
        with:
          name: coverage-reports
          path: coverage-reports/
          
  data-validation:
    runs-on: ubuntu-latest
    needs: test
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ".[dev,test]"
          
      - name: Validate scrapping pipeline schemas
        env:
          PYTHONPATH: ${{ github.workspace }}
          BQ_PROJECT_ID: test-project
          BQ_STAGING_DATASET_ID: test_dataset
          BQ_DESTINATION_DETAILS_TABLE_ID: test_destinations
          GCS_BUCKET_NAME: test-bucket
          GCS_WEATHER_BUCKET_NAME: test-weather-bucket
          TESTING: "true"
        run: |
          cd pipelines/scrapping_dest_details
          python -m pytest tests/test_schema_validation.py -v
          
      - name: Validate data schema consistency
        run: |
          # Check if data schemas have changed unexpectedly
          # You can use Python scripts to validate consistency of:
          # - BigQuery table schemas
          # - CSV/JSON/Parquet file schemas
          # - Data types in pipeline outputs
          echo "Validating data schemas"
          
          # Add your custom schema validation here
          # Example: python -m pipelines.common.validate_schemas
          
  dry-run:
    runs-on: ubuntu-latest
    needs: [test, data-validation]
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ".[dev,test]"
          
      - name: Create mock environment
        run: |
          # Create any necessary mock resources or configs for dry run
          echo "Setting up mock environment"
          mkdir -p ./mock_data
          mkdir -p ./mock_data/scrapping_dest_details
          
      - name: Run scrapping pipeline in dry-run mode
        env:
          DRY_RUN: "true"
          PYTHONPATH: ${{ github.workspace }}
          BQ_PROJECT_ID: test-project
          BQ_STAGING_DATASET_ID: test_dataset
          BQ_DESTINATION_DETAILS_TABLE_ID: test_destinations
          GCS_BUCKET_NAME: test-bucket
          GCS_WEATHER_BUCKET_NAME: test-weather-bucket
          TESTING: "true"
        run: |
          # Mock the config to use test files
          cat > pipelines/scrapping_dest_details/tests/dry_run_config.py << EOL
          # Mock config for dry run
          TRAVEL_DESTINATIONS = ['Paris', 'Rome', 'New York']
          PROJECT_ID = 'test-project'
          DATASET_ID = 'test_dataset'
          TABLE_ID = 'test_destinations'
          BQ_TABLE_PATH = 'test-project.test_dataset.test_destinations'
          BUCKET_NAME = 'test-bucket'
          EOL
          
          # Run the scrapping pipeline in dry-run mode with mock config
          cd pipelines/scrapping_dest_details
          python -c "
          import sys
          import os
          from unittest.mock import patch
          import json
          from pipeline import run_pipeline
          
          # Mock essential external dependencies
          with patch('pipelines.scrapping_dest_details.fetcher.requests.Session'), \\
               patch('pipelines.scrapping_dest_details.gcs_storage._get_bucket'), \\
               patch('pipelines.scrapping_dest_details.bigquery_loader.bigquery.Client'), \\
               patch('pipelines.scrapping_dest_details.pipeline.TRAVEL_DESTINATIONS', ['Paris', 'Rome']):
              
              # Run pipeline in dry mode
              success = run_pipeline()
              print(f'Dry run completed with success={success}')
              if not success:
                  sys.exit(1)
          "
          
      - name: Run pipelines in dry-run mode
        env:
          DRY_RUN: "true"
        run: |
          # Run each pipeline in dry-run mode to verify logic without external dependencies
          echo "Running pipelines in dry-run mode"
          
          # Run weather API pipeline in dry-run mode 
          # python -m pipelines.weather_api_pipeline.pipeline --dry-run
          
          # Run trips data pipeline in dry-run mode
          # python -m pipelines.trips_data.pipeline --dry-run
          
      - name: Validate pipeline outputs
        run: |
          # Validate pipeline outputs for correctness
          echo "Validating pipeline outputs"
          # Add your output validation here
          # Example: python -m pipelines.common.validate_outputs
          
  code-security:
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ".[dev,test]"
          pip install bandit safety
          
      - name: Run security scan
        continue-on-error: true
        run: |
          mkdir -p security-reports
          bandit -r pipelines/ -f json -o security-reports/bandit-results.json || echo "Bandit scan identified security issues. See the report for details."
          
      - name: Check dependencies for vulnerabilities
        continue-on-error: true  
        run: |
          safety check || echo "Safety check identified dependency vulnerabilities. Review the output for details."
          
      - name: Upload security results
        uses: actions/upload-artifact@v4
        with:
          name: security-results
          path: security-reports/
          
      - name: Check for critical security issues
        run: |
          echo "Running post-scan analysis for critical security issues..."
          python -c "
          import json
          import sys
          
          try:
              # Load the bandit results
              with open('security-reports/bandit-results.json', 'r') as f:
                  results = json.load(f)
                  
              # Check for high severity issues
              high_severity_issues = [r for r in results.get('results', []) 
                                     if r.get('issue_severity') == 'HIGH']
                                     
              if high_severity_issues:
                  print(f'CRITICAL: Found {len(high_severity_issues)} high severity security issues!')
                  for issue in high_severity_issues:
                      print(f'- {issue.get(\"filename\")}:{issue.get(\"line_number\")} - {issue.get(\"issue_text\")}')
                  sys.exit(1)
              else:
                  print('No high severity security issues found.')
                  sys.exit(0)
          except Exception as e:
              print(f'Error analyzing security results: {str(e)}')
              # Don't fail the pipeline on analysis error
              sys.exit(0)
          " 