name: Data Pipeline CI

on:
  push:
    branches: [ main, develop ]
    paths:
      - 'pipelines/**'
      - 'pyproject.toml'
      - '.github/workflows/data-pipeline-ci.yml'
  pull_request:
    branches: [ main, develop ]
    paths:
      - 'pipelines/**'
      - 'pyproject.toml'
  workflow_dispatch:
    # Allow manual triggering

jobs:
  lint:
    runs-on: ubuntu-latest
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ".[dev]"
          
      - name: Run code formatting check
        run: |
          black --check pipelines/
          isort --check pipelines/
          
      - name: Run linting
        run: |
          flake8 pipelines/

  test:
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ".[dev]"
          pip install coverage pytest-cov great_expectations
          
      - name: Run tests for all pipelines
        run: |
          mkdir -p junit
          pytest pipelines/ --junitxml=junit/test-results.xml
          
      - name: Run specific scrapping pipeline tests
        run: |
          mkdir -p junit/scrapping_dest_details
          mkdir -p coverage-reports/scrapping_dest_details
          cd pipelines/scrapping_dest_details
          python -m tests.run_tests --with-coverage --junit-xml=../../junit/scrapping_dest_details/test-results.xml --html-report=../../coverage-reports/scrapping_dest_details
          
      - name: Upload test results
        uses: actions/upload-artifact@v3
        if: always()
        with:
          name: test-results
          path: junit/
          
      - name: Upload coverage reports
        uses: actions/upload-artifact@v3
        if: success()
        with:
          name: coverage-reports
          path: coverage-reports/
          
  data-validation:
    runs-on: ubuntu-latest
    needs: test
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ".[dev]"
          pip install pandas great_expectations
          
      - name: Validate scrapping pipeline schemas
        run: |
          cd pipelines/scrapping_dest_details
          python -m pytest tests/test_schema_validation.py -v
          
      - name: Validate data schema consistency
        run: |
          # Check if data schemas have changed unexpectedly
          # You can use Python scripts to validate consistency of:
          # - BigQuery table schemas
          # - CSV/JSON/Parquet file schemas
          # - Data types in pipeline outputs
          echo "Validating data schemas"
          
          # Add your custom schema validation here
          # Example: python -m pipelines.common.validate_schemas
          
  dry-run:
    runs-on: ubuntu-latest
    needs: [test, data-validation]
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install ".[dev]"
          
      - name: Create mock environment
        run: |
          # Create any necessary mock resources or configs for dry run
          echo "Setting up mock environment"
          mkdir -p ./mock_data
          mkdir -p ./mock_data/scrapping_dest_details
          
      - name: Run scrapping pipeline in dry-run mode
        env:
          DRY_RUN: "true"
        run: |
          # Mock the config to use test files
          cat > pipelines/scrapping_dest_details/tests/dry_run_config.py << EOL
          # Mock config for dry run
          TRAVEL_DESTINATIONS = ['Paris', 'Rome', 'New York']
          PROJECT_ID = 'test-project'
          DATASET_ID = 'test_dataset'
          TABLE_ID = 'test_destinations'
          BQ_TABLE_PATH = 'test-project.test_dataset.test_destinations'
          BUCKET_NAME = 'test-bucket'
          EOL
          
          # Run the scrapping pipeline in dry-run mode with mock config
          cd pipelines/scrapping_dest_details
          python -c "
          import sys
          import os
          from unittest.mock import patch
          import json
          from pipeline import run_pipeline
          
          # Mock essential external dependencies
          with patch('pipelines.scrapping_dest_details.fetcher.requests.Session'), \\
               patch('pipelines.scrapping_dest_details.gcs_storage._get_bucket'), \\
               patch('pipelines.scrapping_dest_details.bigquery_loader.bigquery.Client'), \\
               patch('pipelines.scrapping_dest_details.pipeline.TRAVEL_DESTINATIONS', ['Paris', 'Rome']):
              
              # Run pipeline in dry mode
              success = run_pipeline()
              print(f'Dry run completed with success={success}')
              if not success:
                  sys.exit(1)
          "
          
      - name: Run pipelines in dry-run mode
        env:
          DRY_RUN: "true"
        run: |
          # Run each pipeline in dry-run mode to verify logic without external dependencies
          echo "Running pipelines in dry-run mode"
          
          # Run weather API pipeline in dry-run mode 
          # python -m pipelines.weather_api_pipeline.pipeline --dry-run
          
          # Run trips data pipeline in dry-run mode
          # python -m pipelines.trips_data.pipeline --dry-run
          
      - name: Validate pipeline outputs
        run: |
          # Validate pipeline outputs for correctness
          echo "Validating pipeline outputs"
          # Add your output validation here
          # Example: python -m pipelines.common.validate_outputs
          
  code-security:
    runs-on: ubuntu-latest
    needs: lint
    steps:
      - uses: actions/checkout@v4
      
      - name: Set up Python
        uses: actions/setup-python@v5
        with:
          python-version: '3.12'
          cache: 'pip'
      
      - name: Install dependencies
        run: |
          python -m pip install --upgrade pip
          pip install bandit safety
          
      - name: Run security scan
        run: |
          bandit -r pipelines/ -f json -o bandit-results.json
          
      - name: Check dependencies for vulnerabilities
        run: |
          safety check
          
      - name: Upload security results
        uses: actions/upload-artifact@v3
        with:
          name: security-results
          path: bandit-results.json 